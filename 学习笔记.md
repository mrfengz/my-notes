
-----------redis ---------------
*** 内存 ***
	主要内容
		1. 内存消耗分析
		2. 管理内存的原理与方法
		3. 内存优化技巧

	内存使用分析
		命令：info memory	
		
		重要指标 
		1.used_memory_rss # 操作系统角度 内存占用
		2.used_memory # redis数据占用内存总量
		3.mem_fragmentation_ratio used_memory_rss/used_memory，表示内存碎片率
			如果>1,说明多出的部分内用被碎片消耗，相差很大，说明碎片率严重
			如果<1,一般为redis内存交换到硬盘导致，要格外关注。

		消耗划分：
			自身内存 + 对象内存 + 缓冲内存 + 内存碎片 = used_memory+rss
			自身内存 + 对象内存 + 缓冲内存 -》 used_memory

			对象内存
				sizeof(keys)+sizeof(values)
					避免键过长

			缓冲内存
				客户端缓冲+复制积压缓冲区+AOF缓冲区		

*** 复制 *****
	将数据复制多个副本部署到其他机器，满足故障恢复和负载均衡要求，解决单点故障问题。

	建立复制：
		1）配置 slaveof {masterHost} {masterPort}
		2) redis-server --slaveof {masterHost} {masterPort}
		3) slaveof {masterHost} {masterPort} 【也可以切换新主节点】

	查看复制状态
		info replication

	断开复制
		slaveof no one	

	复制验证码
		主节点：requirepass 
		从节点：masterauth

	从节点只读
		slave-read-only=yes|no

	传输延迟
		复制时的网络延迟。
		repl-disable-tcp-nodelay 控制是否关闭 tcp_nodelay
		
		关闭：无论数据大小都会及时发送给从节点，主从延迟变小，增加了网络带宽消耗。适用于主从网络良好，如同机架或同机房部署。
		开启：主节点会合并较小的tcp数据从而节省带宽，间隔取决于linux内核。节省带宽，增大主从延迟。适用于网络情况复杂或者带宽紧张的场景，如跨机房部署。
**从节点部署需要考虑网络延迟、带宽使用率、防灾级别等因素**	

### 拓扑结构
	一主一从
		并发写入量高时，可以只在从节点上开启aof，保持了安全性，又避免了持久化对主节点的性能干扰。
		**注意：主节点关闭持久化时，如果主节点脱机，要避免自动重启操作。从节点：slaveof no one,然后主节点再重启**
	一主多从
		读占比较大，可以把读命令发送到从节点分担主节点压力。
		耗时较长的读命令，可以在从节点上执行，防止慢查询阻塞主节点，影响线上服务的稳定性。
		写并发较高，多个从节点会导致主节点写命令多次发送，过度消耗带宽，也增加了主节点的负载。
	树状主从	
		从节点（相当于中间层）可以从主节点复制数据，还可以作为其他从节点的主节点继续向下层复制。
		
### 复制过程
	1.保存主节点信息（并未连接）
	2.主从建立socket连接
		定时任务每秒检测并连接主节点
	3.发送ping命令
		1）检测主从之间网络套接字是否可用
		2）检测主节点当前是否可接受处理命令
	4.权限验证
	5.同步数据集
		首次连接，全量同步（最耗时）。sync
		2.8+ psync，分为全量同步和部分同步
	6.命令持续写入
	

### 数据同步
	1. 全量复制
		初次复制，主节点全部数据一次性发送给从节点。数据量较大时，会对主从节点和网络造成很大开销
		psync -1: 全量复制
		主节点：+fullresync.主节点执行bgsave, 生成rdb文件，发送给从节点，然后发送buffer
			rdb数据量过大，可能会导致repl-timeout超时（默认60s）,从节点将放弃接受rdb文件并清理已下载的临时文件，全量复制失败
			从节点开始接受rdb快照到完成期间，主节点仍然相应读写命令，写命令保存到复制客户端缓冲区内，当从节点加载完rdb文件后，主节点再把缓冲区内的数据发送给从节点。如果朱从节点传输rdb文件时间过长，容易造成客户端缓冲区溢出，client-output-buffer-limit slave 256m 64m 60，如果60秒内超过64m或者直接超过256m，主节点直接关闭从节点，同步失败。
	2. 部分复制
		主从复制因网络闪断等原因造成的数据丢失场景，从节点再次连接后，如条件允许，主节点补发数据给从节点。

	psync需要的组件支持：
		1. 主从节点各自复制偏移量
			info replication:
			 	master_repl_offset：主节点偏移量
				connected_slaves: offset
				slave_repl_offset: 从节点偏移量	
				master_repl_offset-slave_repl_offset # 偏差
		2. 主节点复制积压缓冲区
			固定长度1M，主从建立后，写命令会同时发送给从节点，也会写入到积压缓冲区中，用于部分复制和复制命令丢失的数据补救
		3. 主节点运行id	
			节点id变化，导致从节点全量复制。
			如果不想改变运行id，可以使用debug reload（会阻塞主线程）
		4. psync命令
			psync {runId} {offset}	
			主节点返回结果：
				1）+fullresync
				2) +continue
				3) -err
			


客户端API
client list
1.qbuf、qbuf-free 客户端输入缓冲区，不受maxmemory限制，固定1G
	缓冲区过大原因：redis处理速度跟不上缓冲输入的速度。redis发生了阻塞。
	处理：1）定期执行client list 
		2) 通过info clients模块，找到最大的输入缓冲区 client_biggest_input_buf,代表最大的输入缓冲区，可设置10M
		两种方法对比
		命令			优点 					缺点
		client list 	精准分析每个客户端		执行速度慢（连接数多尤甚），频繁执行可能阻塞redis
		info clients 	速度快，分析过程简单 	不能精准定位，只显示缓冲区最大量，不显示所有缓冲输入区总量
2。输出缓冲区：obl,oll,omen
	分类：1）普通客户端 2）发布订阅客户端 3）slave客户端	
	配置规则
	client-output-buffer-limit <class> <hard limit> <soft limit> <soft seconds>
	特点：不受maxmemory限制，使用不当同样会造成maxmemory用满产生的数据丢失、键值淘汰、OOM等
情况。
	组成：固定缓冲区（16K）+动态缓冲区
		固定缓冲区：较小结果集，使用字节数组。 obl:固定缓冲区长度
		动态缓冲区：较大缓冲区，hgetall,smembers,较大字符串等。使用列表。 oll:动态缓冲区长度
3. 客户端存活状态
	age: 已连接时间
	idle：最近一次连接后的空闲时间
4.客户端限制
	maxclients： 限制最大连接数。 
		查看： info clients. connected_clients
		注意：使用后及时关闭
	timeout: 	控制连接最大空闲时间，超时会被关闭。

命令：
	client setName, getName
	client kill ip:port	杀掉客户端
	client pause timeout(毫秒) 阻塞连接的客户端。 只对普通和发布订阅客户端有效，slave客户端无效
	monitor 监听redis正在执行的命令，如果客户端有很大的输出缓冲区，可能导致monitor的输出缓冲区暴涨，线上环境不要使用	

相关配置
	timeout
	maxclients
	tcp-keepalive: 检测tcp连接活性的周期，默认为0，就是不检测。设置建议60，防止大量死链接占用系统资源
	tcp-backlog： tcp三次握手后，接受的连接会被放入次队列中。
		修改： echo 511 > /proc/sys/net/core/somaxconn	(如果该值小于redis的配置的话)

常见问题：原因？
	1. 无法从连接池获取连接
	2. 客户端读写超时
	3. 客户端连接超时
	4. 客户端缓冲区异常
	5. Lua脚本正在执行
	6. redis正在加载持久化文件
	7. redis内存超过maxmemory配置
	8. 客户端连接数过大
---------------------------------------------
## HttpIndex模块
	负载平衡：基于IP或者轮询。
	upstream backend{
		ip_hash;	#根据ip分配服务器，同一个客户端请求会被分给同一个服务器
		server backend1.example.com weight=5;	#请求分配权重
		server backend2.example.com:8080;
		server unix:/tmp/backend3;
		server backend4.example.com down;	#服务挂了
	}

	server {
		location / {
			proxy_pass http://backend;
		}
	}

	ip_hash

## HttpAccess模块
	提供了简单的基于主机的访问
	location / {
		:deny 192.168.1.1;
		:allow 192.168.1.0/24;
		:allow 10.1.1.0/16;
		:deny all;
	}

	allow: 放行 
	deny: 禁止
	参数： [address \ CIDR \ all]
	使用地方：http, server, location, limit_except

## HttpAuthBasic模块
	可使你基于用户名和密码，基于http的基本认证方法，保护站点访问或其他内容
	location / {
		: auth_basic "Restricted";
		: auth_basic_user_file conf/htpasswd;
	}

	auth_basic [text \ off]
	auth_basic_user_file filename
		用户名:密码
		用户名2:密码2:注释
		用户名3:密码3

	密码必须使用crypt(3)加密。可使用htpasswd创建密码文件
	
	perl创建密码文件脚本：
		#!/usr/bin/pecl
		use strict;

		my $pw=$ARGV[0];
		print crypt($pw, $pw) . "\n"

		执行
		chmod +x pw.pl
		./pw.pl password

## HttpAutoIndex模块
	用于自动生成目录列表
		ngx_http_autoindex_module只在ngx_http_index_module模块未找到索引文件时发出请求

	location / {
		:autoindex on;	#激活、关闭自动索引
		:autoindex_exact_size on; #设定索引时，文件的大小单位 B，KB,MB或GB
		:autoindex_localtime on;	#开启以本地时间来显示文件时间的功能。默认为关(GMT时间)
	}

## HttpEmptyGif模块
	内存中常驻了一个1x1的透明gif，可以被快速调用

	location = /_.gif {
		: empty_gif;
	}	

## HttpFcgi模块
	允许Nginx与FastCGI进程交互，并通过传递参数控制FastCGI进程工作

	location / {
		fastcgi_pass localhost: 9000;
		fastcgi_index index.php;

		fastcgi_param SCRIPT_FILENAME /home/www/scripts$fastcgi_script_name;
		fastcgi_param QUERY_STRING 	$query_string;
		fastcgi_param REQUEST_METHOD $request_method;
		fastcgi_param CONTENT_TYPE $content_type;
		fastcgi_param CONTENT_LENGTH $content_length;
	}

	fastcgi_buffers 设置缓冲区的数量和大小，用于缓存从fastcgi server接收到的数据。
		fastcgi_buffers the number is_size;
		fastcgi_buffers 8 4k/8k;

	fastcgi_buffer_size
		fastcgi_buffer_size 4k/8k;

	fastcgi_cache 	设置缓存在共享内存中的名称，一块区域可以被用于不同的地方。		
		fastcgi_cache zone;

	fastcgi_cache_key 设置缓存的key
		fastcgi_cache_key localhost:9000 $request_uri;	

	fastcgi_cache_methods  
		[GET HEAD POST]

	fastcgi_cache_min_uses 1
	
	fastcgi_cache_path
		fastcgi_cache_path /path/to/cache [levels=m:n keys_zone=name:time inactive=time clean_time=time]

	fastcgi_cache_use_stale
		fastcgi_cache_use_stale [updating\error\timeout\invalid_header\http_500]
		default: fastcgi_cache_use_stale off;		
	
	fastcgi_cache_valid
		fastcgi_cache_valid [http_error_code|time]

	fastcgi_index
		fastcgi_index file 如果请求为/,则改文件会被附加到URI中，并且被存储到$fastcgi_script_name字段中

	fastcgi_hide_header
		默认情况下，nginx不会从fastcgi进程里给客户端发送 status 和 x-accel-...消息头。可以掩饰别的headers。
		可以使用此指令让fastcgi强制发送消息头给客户端

	fastcgi_ignore_client_abort off
		用来忽略用户请求的消息		

	fastcgi_intercept_errors off
		决定是否腰包客户端转向 4xx和5xx错误页，或允许nginx自动指定错误页

	fastcgi_param
		fastcgi_param parameter value
		该指令指定的参数，将被传给fastcgi-server

****** HttpFcgi模块 ******** 			
location / {
	fastcgi_pass localhost:9000;
	fasgcgi_index index.php;

	fastcgi_param SCRIPT_FILENAME /home/www/scripts/php$fastcgi_script_name;
	fastcgi_param QUERY_STRING $query_string;
	fastcgi_param REQUEST_METHOD $request_method;
	fastcgi_param CONTENT_TYPE $content_type;
	fastcgi_param CONTENT_LENGTH $content_length;
}

fastcgi_buffers 设置缓冲区的数量和大小，用于缓存从 FASTCGI Server接收到的数据。
	默认情况下，一个缓冲区的大小，相当于一个页面的大小。根据不同的平台，设置为4k/8k
	default fastcgi_buffers 8 4k/8k;

fastcgi_buffer_size 
	default: fastcgi_buffer_size 4k/8k
	设置缓冲区大小，从fastcgi——server返回的第一部分会被放到这里

fastcgi_cache 设置缓存在共享内存中的名称，一块区域可以被用在不同的地方
	fastcgi zone 	

fastcgi_cache_key
	设置缓存的key
	fastcgi_cache_key localhost:9000 $request_uri;

fastcgi_cache_methods
	default: fastcgi_cache_methods GET HEAD [POST...]	

fastcgi_cache_min_uses
fastcgi_cache_path
	语法：fastcgi_cache_path /path/to/cache [levels=m:n keys_zone=name:time inactive=time clean_time=time]
fastcgi_cache_use_stale
	语法：fastcgi_cache_use_stale [updating|error|timeout|invalid_header|http_500]
fastcgi_cache_valid
fastcgi_index 名字会被添加到URI后边，并被保存到$fastcgi_script_name如果URI以/结束

## geo模块
	根据客户端的ip地址，创建变量

## HttpGzip模块
	使用范例
	gzip on;
	gzip_min_length 1000;
	gzip_proxied expired no-cache no-store private auth;
	gzip_types text/plain application/x-javascript text/css text/html application/xml;
	
	内置变量 $gzip_ratio可以控制压缩比例

	gzip on/off 开关
	gzip_buffers 用几个单位的缓存空间，存储压缩后的数据流
		gzip_buffers 4 4k/8k. 	不设置，则与原始数据大小相同内存存储压缩结果。4个4k， 4个8k
	gzip_comp_level 压缩级别
		1-9 1压缩最少，速度快。9压缩最大，速度慢，比较消耗cpu
	gzip_min_length 允许压缩的页面的最小字节数，length取header中的content-length，建议大于1k=1024	
	gzip_proxied nginx作为反向代理的时候启用，开启或者关闭后端服务器返回的结果，匹配的前提是后端服务器必须要返回包含“Via”的header头
		off - 关闭所有的代理结果数据的压缩
		expired - 启用压缩，如果header头中包含 "Expires" 头信息
		no-cache - 启用压缩，如果header头中包含 "Cache-Control:no-cache" 头信息
		no-store - 启用压缩，如果header头中包含 "Cache-Control:no-store" 头信息
		private - 启用压缩，如果header头中包含 "Cache-Control:private" 头信息
		no_last_modified - 启用压缩,如果header头中不包含 "Last-Modified" 头信息
		no_etag - 启用压缩 ,如果header头中不包含 "ETag" 头信息
		auth - 启用压缩 , 如果header头中包含 "Authorization" 头信息
		any - 无条件启用压缩
	gzip_types 匹配MIME类型进行压缩，text/html总会被压缩
		注意：如果作为http server来使用，主配置文件中要包含文件类型配置文件
		http
		{
			include       conf/mime.types;
			......
		}	

## HttpHeaders模块
	示例
	expires 24h; //0 -1
	expires epoch;
	add_header Cache-Control private;

	add_header name value 为指定状态添加http头
		当状态码为200， 204,301， 302， 304时，添加指定的http头

## HttpIndex模块
	index file [file...]
	示例
		index index.$geo.html index.0.html /index.html

## HttpReferer模块
	可以根据Referer来阻塞不正确的请求。不过标准的浏览器，可能也不发送referer头
	location /photos/ {
		valid_referers none blocked www.mydomain.com mydomain.com;
		if ($invalid_referer) {
			return 403;
		}
	}				

## HttpLimit zone模块，针对条件，进行会话的并发连接数控制
	示例
	http {
		limit zone one $binary_remote_addr 10m;

		server {
			location /download/ {
				limit_conn one 1;
			}
		}
	}

	limit_zone 指定了一个数据区，里面记录会话状态信息
		语法 limit_zone zone_name $variable the_size
		$variable定义判断会话的变量； the_size定义记录区的总容量
		$binary_remote_addr 比 $remote_addr更省长度

	limit_conn 指定一个会话最大的并发连接数。超过指定的并发数时，服务器将返回503， service unavaliable	
		限制/download/目录下，一个会话只能进行一个连接
		location /download/ {
			limit_conn one 1;
		}

## HttpLimitReqest模块
	示例
	http {
		limit_req_zone $binary_remote_addr zone=one;10m rate=1r/s;
		...
		server {
			...
			location /search/ {
				limit_req zone=one burst=5;
			}
		}
	}

	limit_req_zone $session_variable zone=name_of_zone;size rate=rate;
		limit_req_zone $binary_remote_addr zone=one;10m rate=1r/s; 
		分配10m给session state变量存储区域。请求频率为1秒/次

	令牌桶算法，超过指定的访问频次后，放在burst指定的桶长度中，不过只有5个位置，再多就返回503
	如果配置 burst=5 nodelay 瞬时超过 rate+burst数量后，直接返回503，不需要等待	

## HttpLog模块
	示例
	log_format  gzip  '$remote_addr - $remote_user [$time_local]  '
		: '"$request" $status $bytes_sent '
		: '"$http_referer" "$http_user_agent" "$gzip_ratio"';
	access_log  /spool/logs/nginx-access.log  gzip  buffer=32k;

---------------------------------------------
## 高性能Mysql
	mysql最重要的特性：
		存储引擎架构： 查询处理、其他系统任务、数据的存储和提取相分离
	
	逻辑架构图
		客户端——>连接/线程处理——>查询缓存
							   |	
							  ——>解析器——>优化器   ->存储引擎
	最上层服务：连接处理、授权认证、安全等(大多数基于网络的客户端、服务器工具都有)
	第二层架构：mysql的核心功能。 查询解析、分析、优化、缓存和所有内置函数
		跨存储引擎功能：存储过程、触发器、视图等
	第三层：存储引擎。数据的存储和提取	
		服务器通过API与存储引擎通信。

	客户端——>服务器进程中拥有对应线程——>单独查询、缓存线程
	

	##### 优化与执行
		重写查询、决定表的读取顺序、选择合适的索引等
		存储引擎会影响优化查询。优化器会请求存储引擎提供容量或者某个具体操作的开销信息
		
		
	### 并发控制
		一般是通过读写锁实现的。写锁是排他的，防止写的过程中被读到，读锁是共享的

		锁粒度： 锁定数量越少，并发程度越高
			行锁：Innodb、XtraDB. 存储引擎层实现
			表级锁

			锁的各种操作都会增加系统开销，包括获取锁、检查锁是否解除、释放锁等
	
	#### 事务
		事务就是一组原子性的sql查询，要么全部执行成功，要么全部执行失败。

		start transaction;
		sql1
		sql2
		commit/rollback;

		ACID:
			原子性
			一致性：从一个一致性状态转换到另一个一致性的状态
			隔离性：一个事务的修改在最终提交前，对其他事务是不可见的
			持久性
		
		隔离级别
			1. read uncommitted: 未提交读
				事务未提交，另一个事务可以读取
			2. read committed: 提交读
				一个事务开始时，只能看见已经提交的事务所做的修改。
				也叫不可重复读，因为执行两次同样的查询，可能会得到不一样的结果
			3. repeatable: 可重复读
				解决了藏读的问题，保证了在同一个事务中，多次读取同一个记录的结果是一致的。
				但是还有幻读的问题。
				【幻读】当某个事务在读取某个范围的记录时，另外一个事务又在该范围内插入了新的记录，当前事务再次读取该范围的记录时，会产生幻行。
				Innodb和XtraDB通过多版本并发控制(MVCC)解决了该问题。
			4. serializable: 可串行化
				最高隔离级别，强制事务串行化。
				【问题】每行数据加锁，导致大量超时和锁争用的问题。实际很少用

		死锁
			死锁指两个或者多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环的现象。
			产生可能性：
				1.多个事务以不同顺序锁定资源时，可能产生死锁
				2.多个事务同时锁定同一个资源时，也会产生死锁

			死锁检测和死锁超时机制

		事务日志
			能提高效率。
			【预写式日志Write-Ahead Logging】存储引擎修改数据时，只要修改其内存拷贝，再把该修改行为记录到持久在硬盘上的事务日志中，而不用每次都把数据持久到磁盘中。
			写日志是磁盘上一小块区域的顺序IO，而不需要随机IO在多个地方移动磁头。
			事务日志持久后，内存中的数据可以慢慢刷回到磁盘
			
			修改数据需要些两次磁盘。
			如数据为持久到到磁盘，存储引擎在重启时能自动修复这部分数据

		支持事务的存储引擎
			InnoDB， NDB Cluster

		事务配置
			show variables like 'autocommit'
			1: 自动提交
			0：禁用自动提交 	

			设置事务级别
				set transaction isolation level read committed;	#下一个事务开始时生效
		
		在事务中不要混合使用存储引擎，非事务更改无法撤销

		显示锁定与隐式锁定
			显式： select ... lock in share mode
				select ... for update

		Innodb中，不要使用lock tables, unlock tables,严重影响性能
		
	#### MVCC
		是通过保存数据在某个时间点的快照实现的。
		根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。			
		
		InnoDB实现：每行记录添加两个隐藏列，一个保存行的创建时间(系统版本号)，一个保存过期时间(或删除时间)
		每开启一个新事物，版本号都会自动递增

		MVCC只在Repeatable read和read committed两个隔离级别下工作

	#### 存储引擎
		schema:
		show table status	

		MyISAM：
			结构：.MYI .MYD .FRM
			支持全文索引
			延迟更新索引键 DELAY_KEY_WRITE
			检查表、修复表
			压缩表：创建或导入后，不能修改
			表锁
		Innodb

		Archive引擎
			支持insert和select操作，并利用zlib压缩插入行，磁盘IO少，但每次查询都会全表扫描
			适合日志和数据采集类应用
			支持行级锁和专用缓冲区，可以高并发写。但是在一个select开始直到返回所有行之前，会阻塞其他的select执行
		CSV存储引擎
			将普通的csv文件，作为mysql的表来处理	
		Memory
			临时表：create temporary table
			mysql在执行查询过程中，需要使用临时表保存中间结果，就是使用的memroy表，如果中间表大大超出了memory表的限制，或含有blob或者text字段，则临时表会转换成myisam表
		Merge
		NDB集群引擎
		Blackhole
		Federated引擎

		第三方引擎
			1.OLTP类引擎
				XtraDB，可作为innodb的完全替代品
				PBXT

		日志型应用
			要求速度较快，可以使用myisam或archive，但是如果作分析，这就不合适了。
			1.可以通过mysql内置的复制方案，将数据复制一份到备库，在备库上执行查询
			2. 将日志按照年月或其他指标再具体处理，这样就不会影响插入了

		修改存储引擎
			1. alter table 表名 engine=innodb. 
				将数据复制到新表，可能会消耗系统所有的IO，同时原表会加锁
			2. 导出与导入
			3. create select	
				create table table1 like table2
				alter table table1 engine=innodb
				insert into table1 select * from table2 (where id between 1 and 1000)
	#### 检查服务器状态
		show status like xx
		show global status
		demo: show global status like 'select%'

## 测试
	指标
		1.吞吐量
			单位时间内的事务处理数. 
			TPS:每秒事务数
			TPM:每分钟事务数
		2. 响应时间数或者延迟 latency
			平均响应时间、最大响应时间、最小响应时间和所占百分比	
		3. 并发性
			web的高并发不表示数据库的高并发	
			并发性基准测试需要关注的是：正在工作中的并发操作、同时工作中的线程数或者连接数	

	收集测试结果
		#!/bin/sh

		INTERVAL=5
		PREFIX=$INTERVAL-sec-status
		RUNFILE=/home/benchmarks/running
		mysql -e 'SHOW GLOBAL VARIABLES' >> mysql-variables

		while test -e $RUNFILE; do
			file=$(date +%F_%I)
			sleep=$(date + %s.%N | awk "{print $INTERVAL - (\$1 % $INTERVAL)}")	
			sleep $sleep
			ts="$(date+"TS %s.%N %F %T")"
			loadavg="$(uptime)"
			echo "$ts $loadavg" >> $PREFIX-${file}-status
			mysql -e 'show global status' >> $PREFIX-${file}-status &
			echo "$ts $loadavg" >> $PREFIX-${file}-innodbstatus
			mysql -e 'show engine innodb status\G' >> $PREFIX-${file}-innodbstatus &
			echo "$ts $loadavg" >> $PREFIX-${file}-processlist
			mysql -e 'show full processlist\G' >> $PREFIX-${file}-processlist &
			echo $ts
		done
		
		echo Exiting because $RUNFILE does not exists

	自动化分析结果		
		#!/bin/sh
		# 改脚本会分析show global status结果
		awk '
			BEGIN {
				printf "#ts date time load QPS";
				fmt = " %.2f";
			}
			/^TS/ { #时间戳以TS开头
				ts = substr($2, 1, index($2, ".") - 1);
				load = NF - 2;
				diff = ts - prev_ts;
				prev_ts = ts;
				printf "\n%s %s %s %s", ts, $3, $4, substr($load, 1, length($load) - 1);
			}
			/Queries/ {
				printf fmt, ($2-Queries)/diff;
				Queries=$2;
			}
			' "$@"

		将结果绘制成图形
		gnuplut > plot "QPS-per-5-seconds" use 5 w lines title "QPS"
	
	#### 测试工具
		1.集成测试工具
		ab	测试单个url
		http_load 可以通过一个文件，提供多个url进行测试
		JMeter
		2.单组件式测试工具
			mysqlslap
			mysql benchmarksuite 只能测试单cpu，因为是单线程且串行执行
			super smack
			database test suite
			sysbench

## http和https的区别
	ssl(安全套接层)/tls(传输层安全协议) 在应用层和传输层之间	
	https: http + ssl / tls


	常见的加密算法：
		1. 对称加密
			加密和解密使用相同的密钥
			加解密速度快，但是秘钥的管理和分发负担比较重
		2. 非对称加密
			加密和解密使用不同的密钥，分别为公钥和私钥。公钥可以公开，私钥不可以公开。
			加密速度慢，只需要发送公钥
		3. hash算法
			通过hash算法，对目标信息生成一段特定长度的唯一的hash值，却不能通过这个hash值重新获得目标信息。
----------------------------------------------------------

----------------	




----------------------------------------------------------
## DNS域名解析
	1.浏览器DNS缓存
	2.操作系统DNS缓存
	3.hosts文件
	4.DNS服务器		

	一次http请求
		1.DNS域名解析
		2.建立TCP连接：三次握手
		3.客户端发起http请求
			请求行、请求头、请求体
		4.客户端接收web服务器响应结果
			响应行、响应头、响应体
		5.浏览器解析响应内容：渲染html内容
		6.关闭tcp连接：四次挥手

## 常见HTTP状态码
	状态码说明
		# HTTP状态码的第一个数字定义了响应的类别, 第一个数字有5种可能的取值
		1XX: 请求已接收, 需要继续处理 
		2XX: 请求已成功被服务器处理完毕
		3XX: 为完成请求, 客户端需要进一步操作以完成请求
		4XX: 客户端请求出错
		5XX: 服务端处理请求出错

	常见状态码
		200(正常): 
		服务端返回正常的请求结果

		301(永久重定向):  
		请求的资源被分配了新的URL, 该URL是响应头Location的值, 以后使用新的URL去请求该资源

		302(临时重定向):
		请求的资源被分配了新的URL, 该URL是响应头Location的值, 本次使用新的URL去请求该资源, 以后的请求仍然使用原来的URL

		304(未修改Not Modified):
		如果客户端有缓存的资源, 在请求该资源时会在请求头中附加If-Modified-Since的请求头
		只有请求的资源在If-Modified-Since指定的时间之后发生过更改, 服务端才返回新的资源
		状态码304表示客户端缓存的资源是最新的, 客户端应该使用缓存资源

		403(禁止):
		服务端拒绝客户端的请求, 通常是服务端的文件权限不足

		404(找不到资源):
		服务端没有客户端请求的资源

		500(服务器内部错误):
		服务器内部错误, 通常是程序发生了错误

		502(无效网关):
		如果是LNMP架构, 通常是Nginx和FPM通信出错导致

		503(服务不可用):
		服务器目前过载或者处于维护状态	



